<center> Proyecto Llama AI ğŸš€ </center>
Este proyecto tiene como objetivo implementar un sistema de inteligencia artificial utilizando el modelo Llama AI para interactuar con usuarios y proporcionar respuestas basadas en informaciÃ³n proporcionada. AdemÃ¡s, se desarrolla una aplicaciÃ³n Flask para integrar capacidades como procesamiento de archivos PDF, cÃ¡lculo de embeddings de texto y respuesta a consultas.

Fases del Proyecto
InteracciÃ³n con Ollama ğŸ¤–

InstalaciÃ³n de Ollama y configuraciÃ³n del modelo Llama3.
EjecuciÃ³n del modelo y prueba de funcionalidad.
Creando Estructura de la App ğŸ› ï¸

ConfiguraciÃ³n de un ambiente aislado de Python.
InstalaciÃ³n de dependencias necesarias para la aplicaciÃ³n Flask.
Interactuando con el LLM ğŸ’¬

IntegraciÃ³n del modelo Llama3 para responder preguntas en la aplicaciÃ³n Flask.
Integrando Capacidad de Subir PDF ğŸ“„

AdiciÃ³n de funcionalidad para procesar archivos PDF en la aplicaciÃ³n.
Agregar Embeddings ğŸ”

ImplementaciÃ³n de embeddings de texto para mejorar la respuesta del modelo.
Agregar Model Response ğŸ“

Desarrollo de un sistema de respuesta basado en la informaciÃ³n proporcionada.
EjecuciÃ³n del Proyecto
Para ejecutar este proyecto localmente, sigue estos pasos:

Clona el repositorio desde GitHub.
Instala las dependencias necesarias utilizando python -m pip install -r requirements.txt.
Ejecuta la aplicaciÃ³n Flask utilizando python app.py.
InteractÃºa con la aplicaciÃ³n a travÃ©s de las URL proporcionadas para probar diferentes funcionalidades.
Â¡Disfruta explorando la inteligencia artificial con Llama AI en este proyecto! ğŸ”¥
