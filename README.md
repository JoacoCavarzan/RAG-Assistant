<center> Proyecto Llama AI 🚀 </center>
Este proyecto tiene como objetivo implementar un sistema de inteligencia artificial utilizando el modelo Llama AI para interactuar con usuarios y proporcionar respuestas basadas en información proporcionada. Además, se desarrolla una aplicación Flask para integrar capacidades como procesamiento de archivos PDF, cálculo de embeddings de texto y respuesta a consultas.

Fases del Proyecto
Interacción con Ollama 🤖

Instalación de Ollama y configuración del modelo Llama3.
Ejecución del modelo y prueba de funcionalidad.
Creando Estructura de la App 🛠️

Configuración de un ambiente aislado de Python.
Instalación de dependencias necesarias para la aplicación Flask.
Interactuando con el LLM 💬

Integración del modelo Llama3 para responder preguntas en la aplicación Flask.
Integrando Capacidad de Subir PDF 📄

Adición de funcionalidad para procesar archivos PDF en la aplicación.
Agregar Embeddings 🔍

Implementación de embeddings de texto para mejorar la respuesta del modelo.
Agregar Model Response 📝

Desarrollo de un sistema de respuesta basado en la información proporcionada.
Ejecución del Proyecto
Para ejecutar este proyecto localmente, sigue estos pasos:

Clona el repositorio desde GitHub.
Instala las dependencias necesarias utilizando python -m pip install -r requirements.txt.
Ejecuta la aplicación Flask utilizando python app.py.
Interactúa con la aplicación a través de las URL proporcionadas para probar diferentes funcionalidades.
¡Disfruta explorando la inteligencia artificial con Llama AI en este proyecto! 🔥
